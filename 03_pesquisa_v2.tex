% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
  english,
]{beamer}
\newif\ifbibliography
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% remove section numbering
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{section title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{subsection title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}

\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
\usepackage{caption}
% Make caption package work with longtable
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother



\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\ifLuaTeX
  \usepackage[english]{selnolig} % disable illegal ligatures
\fi


\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Projeto de Pesquisa},
  pdfauthor={ Ãrea: 1.a. Aprendizagem EstatÃ­stica e CiÃªncia de Dados   Ãrea correlata: 1.c. EstatÃ­stica Computacional     Magno T. F. Severino },
  pdflang={en},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}


\title{Projeto de Pesquisa}
\subtitle{ Unsupervised Learning of Graph Structures: Inference and
Model Selection for High-Dimensional Stochastic Processes}
\author{\\
Ãrea: 1.a. Aprendizagem EstatÃ­stica e CiÃªncia de Dados Ãrea correlata:
1.c. EstatÃ­stica Computacional\\
\strut \\
Magno T. F. Severino}
\date{}

\begin{document}
\frame{\titlepage}


\begin{frame}{Agenda}
\phantomsection\label{agenda}
\begin{itemize}
\item
  Introduction
\item
  Theorethical Background
\item
  Research Proposal
\item
  Viability
\end{itemize}
\end{frame}

\begin{frame}{Motivation}
\phantomsection\label{motivation}
Modern dependence analysis involves:

\begin{itemize}
\tightlist
\item
  high dimensionality,
\item
  temporal dependence,
\item
  continuous data,
\item
  complex structures.
\end{itemize}

\pause

These challenges arise naturally in modern data science problems,
including multivariate time series, sensor networks, neurodata, and
large-scale systems where statistical models must remain both
theoretically sound and computationally scalable.

\pause

Probabilistic graphical models (MRFs) are a natural tool for
representing such dependencies.

\pause

\textbf{Challenge}: existing methods mostly address:

\begin{itemize}
\tightlist
\item
  discrete data,
\item
  a finite number of vertices,
\item
  independence or weak dependence structures.
\end{itemize}
\end{frame}

\begin{frame}{Recent Work}
\phantomsection\label{recent-work}
\begin{columns}[T]
\begin{column}{0.1\linewidth}
{ðŸ“„}
\end{column}

\begin{column}{0.9\linewidth}
{ \textbf{Model selection for Markov random fields on graphs under a
mixing condition}\\
\emph{Stochastic Processes and their Applications}, 2025.\\
\textbf{Severino, M. T. F.}, \& Leonardi, F.\\
}
\end{column}
\end{columns}

\pause

Advances:

\begin{itemize}
\tightlist
\item
  global criterion based on penalized pseudo-likelihood;
\item
  consistency theorem under a mixing condition;
\item
  applications to discrete multivariate processes.
\end{itemize}

\pause

Limitations:

\begin{itemize}
\tightlist
\item
  restriction to the \textbf{finite} vertex case,
\item
  \textbf{discrete} variables.
\end{itemize}

\pause

This project aims to overcome both limitations in \textbf{two
proposals}.
\end{frame}

\section{Background and Definitions}\label{background-and-definitions}

\begin{frame}{Vector Processes and the Underlying Graph}
\phantomsection\label{vector-processes-and-the-underlying-graph}
Consider the vector-valued process:

\[
\mathbf{X}^{(i)} = (X_1^{(i)},\dots,X_d^{(i)}), \qquad i\in\mathbb{N}, \quad X_i \in A.
\]

Assume:

\begin{itemize}
\tightlist
\item
  stationarity,
\item
  existence of an invariant distribution \(\pi\), probability space
  \(\big((A^d)^\mathbb{N}, \mathcal{F}, \mathbb{P}\big),\)
\item
  conditional dependencies described by a graph \(G^* = (V, E^*)\).
\end{itemize}

This graph encodes: \[
X_v \perp X_{V\setminus(\{v\}\cup G^*(v))} \mid X_{G^*(v)}.
\] \(G^*(v) = \{u \in V: (u, v) \in E^*\}.\)
\end{frame}

\begin{frame}{Mixing Condition}
\phantomsection\label{mixing-condition}
\begin{itemize}
\item
  \(X^{(i:j)}\) denote the sequence of vectors
  \(X^{(i)}, X^{(i+1)}, \ldots, X^{(j)}.\)
\item
  \(\bf X = \{X^{(i)}\colon -\infty < i < \infty\}\) satisfies a
  \emph{mixing condition} with rate
  \(\{\psi(\ell)\}_{\ell \in \mathbb R}\) if \begin{equation*}
  \begin{split}
    \Bigl| \mathbb P \bigl(X^{(n:(n+k-1))}=x^{(1:k)}\, |\, X^{(1:m)}=x^{(1:m)}&\bigr) - \mathbb P \bigl( X^{(n:(n+k-1))} =x^{(1:k)}\bigr)\Bigr| \\ 
    &\leq \psi(n-m) \mathbb P\bigl(X^{(n:(n+k-1))}=x^{(1:k)}\bigr),
  \end{split}
  \end{equation*} for \(n\geq m+\ell\) and for each
  \(k, m \in \mathbb N\) and each \(x^{(1:k)} \in (A^d)^k\),
  \(x^{(1:m)}\in (A^d)^m\) with \(\mathbb P(X^{(1:m)}=x^{(1:m)})>0.\)
\end{itemize}

\begin{columns}[T]
\begin{column}{0.7\linewidth}
\begin{center}
\pandocbounded{\includegraphics[keepaspectratio]{03_pesquisa_v2_files/figure-beamer/unnamed-chunk-2-1.pdf}}
\end{center}
\end{column}

\begin{column}{0.3\linewidth}
\[
|\mathbb P(A|B) - \mathbb P(B) \leq \mathbb P(A)|
\] \[
\qquad \leq \psi(n-m)\mathbb P(A)
\]
\end{column}
\end{columns}
\end{frame}

\begin{frame}{\includegraphics[width=1.25em,height=1em]{03_pesquisa_v2_files/figure-beamer/fa-icon-d1a7660eb243c31f97c45bd51d9d48dd.pdf}
Empirical Probabilities}
\phantomsection\label{empirical-probabilities}
\begin{columns}[T]
\begin{column}{0.6\linewidth}
Given a graph \(G=(V,E)\) and \(v \in V,\) define
\[G(v) = \big\{u \in V: (u,v) \in E \big\},\] the set of neighbors of
\(v\) in graph \(G.\)

For \(v=X_1,\) then \(G(v)=\{X_2, X_3\}.\)
\end{column}

\begin{column}{0.3\linewidth}
\includegraphics[width=1.8\linewidth,height=\textheight,keepaspectratio]{img/ex1_graph.png}
\end{column}
\end{columns}

Then \begin{equation*}
    \widehat\pi(a_v|a_{G(v)})  = \frac{\widehat\pi(a_{\{v\}\cup G(v)})}{\widehat\pi(a_{G(v)})}.
\end{equation*}
\end{frame}

\begin{frame}{Penalized Pseudo-Likelihood}
\phantomsection\label{penalized-pseudo-likelihood}
For a candidate graph \(G\): \[
\log L(G)
=
\sum_{v\in V}
\sum_{a_v}\sum_{a_{G(v)}}
N(a_v,a_{G(v)})
\log \pi(a_v\mid a_{G(v)}).
\]

We estimate \(\pi\) empirically: \[
\log \widehat L(G)
=
\sum_{v\in V}
\sum_{a_v}\sum_{a_{G(v)}}
N(a_v,a_{G(v)})\,
\log \widehat\pi(a_v\mid a_{G(v)}).
\]

Selection criterion (Severino \& Leonardi, 2025): \[
\widehat G = \arg\max_G
\big\{\log\widehat L(G) - \lambda_n \sum_{v\in V}|A|^{|G(v)|}\big\}.
\]
\end{frame}

\begin{frame}{Consistency Theorem}
\phantomsection\label{consistency-theorem}
\textbf{Theorem (Severino \& Leonardi, 2025, Stochastic Processes and
their Applications):}

Let \(\{X^{(i)}: i \in \mathbb{N}\}\) be a stationary process that
satisfies the mixing condition presented before with rate
\(\psi(\ell) = O(1/\ell^{1+\epsilon})\) for some \(\epsilon>0.\)

Then, by taking \(\lambda_n = c \log n,\) for \(c>0,\) we have that
\begin{equation*}
  \widehat G = \underset{G}{\arg\max}\Big\{\log \widehat L(G) - \lambda_n \sum_{v \in V} |A|^{|G(v)|}\Big\}
\end{equation*} satisfies \(\widehat G=G^*\) eventually almost surely as
\(n\to \infty.\)
\end{frame}

\section{Proposal 1}\label{proposal-1}

\begin{frame}{Model Selection for MRFs with Countably Infinite Vertex
Sets under Mixing Condition }
\phantomsection\label{model-selection-for-mrfs-with-countably-infinite-vertex-sets-under-mixing-condition}
\textbf{Motivation}:

\begin{itemize}
\tightlist
\item
  Massive networks (social, biological, IoT),
\item
  Structures where \(|V| = \infty\) and grows with the sample,
\item
  Finite-vertex methods do not generalize automatically.
\end{itemize}

\textbf{Existing methods}

\begin{itemize}
\tightlist
\item
  \textbf{Leonardi et al.~(2023)}: Penalized pseudo-likelihood for
  discrete MRFs. Graph estimated based on local neighborhood estimation.
\item
  \textbf{Severino \& Leonardi (2025)}: Developed theoretical results
  for global estimation of discrete MRFs over finite graphs.
\end{itemize}

\textbf{Objective}:

\begin{itemize}
\tightlist
\item
  Extend the penalized pseudo-likelihood framework to
  \(V = \{1,2,\dots\}.\)
\end{itemize}
\end{frame}

\begin{frame}{Proposal 1 -- Main questions:}
\phantomsection\label{proposal-1-main-questions}
\begin{itemize}
\tightlist
\item
  error control when restricting to \(V_n\),
\item
  consistency limits for global estimators,
\item
  adaptation of typicality arguments to infinite vertex sets.
\end{itemize}
\end{frame}

\begin{frame}{Proposal 1 -- Expected Advances}
\phantomsection\label{proposal-1-expected-advances}
\textbf{Proposed estimation framework}:

\begin{itemize}
\tightlist
\item
  Let \(V\) be infinite and \({V_n}, {n \in \mathbb{N}}\) be a sequence
  of finite subsets of \(V\).
\item
  Assume \(V_n \uparrow V\) as \(n \to \infty\).
\item
  Sample: \(\{\mathbf{X} = \{X_v: v \in V_n\}\}\), assuming that
  \({\mathrm{ne}(v)}\) is finite.
\item
  Adaptation of key theorems to handle countably infinite vertex sets.
\end{itemize}

Algorithms:

\begin{itemize}
\tightlist
\item
  implementation in R or Python,
\item
  simulations on large synthetic networks.
\end{itemize}

Applications:

\begin{itemize}
\tightlist
\item
  social networks,
\item
  neuroscience (large neural connectivity),
\item
  sensor systems.
\end{itemize}
\end{frame}

\section{Proposal 2}\label{proposal-2}

\begin{frame}{Model Selection for \textbf{Continuous} MRFs under Mixing}
\phantomsection\label{model-selection-for-continuous-mrfs-under-mixing}
Current limitations:

\begin{itemize}
\tightlist
\item
  classical pseudo-likelihood is defined for finite alphabets,
\item
  discretization leads to information loss.
\end{itemize}

Objective:

\begin{itemize}
\tightlist
\item
  develop a consistent estimator \textbf{without discretization}.
\end{itemize}

Challenges:

\begin{itemize}
\tightlist
\item
  replacing summations with integrals,
\item
  defining neighborhood structure in conditional densities,
\item
  adapting consistency proofs to the continuous setting.
\end{itemize}
\end{frame}

\begin{frame}{Proposal 2 -- Impact}
\phantomsection\label{proposal-2-impact}
Benefits:

\begin{itemize}
\tightlist
\item
  higher inferential precision,
\item
  no discretization required,
\item
  applicability to finance, hydrology, neuroscience, and bioinformatics.
\end{itemize}

Expected results:

\begin{itemize}
\tightlist
\item
  consistency theorems analogous to the discrete case,
\item
  scalable algorithm,
\item
  R or Python package.
\end{itemize}
\end{frame}

\section{Final Integration}\label{final-integration}

\begin{frame}{Final Integration}
Medium-term goal: \[
\text{Continuous MRFs} + \text{Infinite Vertex Sets} + \text{Mixing}.
\]

Deliverables:

\begin{itemize}
\tightlist
\item
  unified theoretical framework,
\item
  consistent algorithms for genuinely large-scale systems,
\item
  general framework for complex real-world data.
\end{itemize}
\end{frame}

\begin{frame}{Viability}
\phantomsection\label{viability}
\textbf{Resources}:

\begin{itemize}
\tightlist
\item
  consolidated background in MRFs, mixing processes, and asymptotic
  theory,
\end{itemize}

\begin{itemize}
\item
  access to computational infrastructure at IME-USP (low budget
  project),
\item
  a collaborative research environment (Neuromat, UFRJ, UFRN, UBA).
\end{itemize}

\textbf{Expected output}:

\begin{itemize}
\item
  two international journal articles,
\item
  two R or Python packages,
\item
  presentations at scientific conferences.
\end{itemize}
\end{frame}

\begin{frame}{\includegraphics[width=1.25em,height=1em]{03_pesquisa_v2_files/figure-beamer/fa-icon-5b9684ddaa4b88f0bb27f469a3e364a2.pdf}
Timeline}
\phantomsection\label{timeline}
\pandocbounded{\includegraphics[keepaspectratio]{img/gantt_chart.png}}
\end{frame}

\begin{frame}{\includegraphics[width=0.75em,height=1em]{03_pesquisa_v2_files/figure-beamer/fa-icon-bce4837ddfe08528a7f6102b08b1e5c3.pdf}
References}
\phantomsection\label{references}
\begin{itemize}
\item
  \textbf{Severino, M. T. F.}, \& Leonardi, F. (2025). \emph{Model
  selection for Markov random fields on graphs under a mixing
  condition}. Stochastic Processes and their Applications.
\item
  Leonardi, F., Lopez-Rosenfeld, M., Rodriguez, D., \textbf{Severino, M.
  T. F. S.}, \& Sued, M. (2021). \emph{Independent block identification
  in multivariate time series}. Journal of Time Series Analysis.
\item
  Leonardi, F., Carvalho, R., \& Frondana, I. (2023). \emph{Structure
  recovery for partially observed discrete Markov random fields on
  graphs under not necessarily positive distributions}. Scandinavian
  Journal of Statistics.
\item
  Lauritzen, S. L. (1996). \emph{Graphical models}. Claredon Press.
\item
  Oodaira, H., \& Yoshihara, K. I. (1971). \emph{The law of the iterated
  logarithm for stationary processes satisfying mixing conditions}.
  Kodai Mathematical Seminar Reports.
\end{itemize}
\end{frame}




\end{document}
